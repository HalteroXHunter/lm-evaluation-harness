/data/research/sharedData/conda_envs/iborrego-lmeval-newnewtask/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `PYTORCH_PRETRAINED_BERT_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/data/research/sharedData/conda_envs/iborrego-lmeval-newnewtask/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `PYTORCH_TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/data/research/sharedData/conda_envs/iborrego-lmeval-newnewtask/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
2025-01-09:13:12:32,186 INFO     [__main__.py:279] Verbosity set to INFO
2025-01-09:13:12:56,687 WARNING  [__main__.py:312]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-01-09:13:12:56,688 INFO     [__main__.py:364] Passed `--trust_remote_code`, setting environment variable `HF_DATASETS_TRUST_REMOTE_CODE=true`
2025-01-09:13:12:56,763 INFO     [__main__.py:376] Selected Tasks: ['vaxxstance_2021']
2025-01-09:13:12:56,785 INFO     [evaluator.py:164] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
2025-01-09:13:12:56,785 INFO     [evaluator.py:201] Initializing hf model, with arguments: {'pretrained': 'EleutherAI/pythia-2.8b', 'trust_remote_code': True, 'parallelize': True, 'max_length': 2048}
2025-01-09:13:12:57,741 INFO     [huggingface.py:356] Model parallel was set to True, setting max memory per GPU to {0: 49590239232, 1: 50759598080} and device map to auto
The `GPTNeoXSdpaAttention` class is deprecated in favor of simply modifying the `config._attn_implementation`attribute of the `GPTNeoXAttention` class! It will be removed in v4.48
2025-01-09:13:13:01,970 WARNING  [task.py:812] [Task: vaxxstance_2021] metric acc is defined, but higher_is_better is not. using default higher_is_better=True
2025-01-09:13:13:01,970 WARNING  [task.py:812] [Task: vaxxstance_2021] metric f1 is defined, but higher_is_better is not. using default higher_is_better=True
2025-01-09:13:13:04,880 INFO     [task.py:415] Building contexts for vaxxstance_2021 on rank 0...
  0%|          | 0/1000 [00:00<?, ?it/s] 16%|█▌        | 162/1000 [00:00<00:00, 1619.59it/s] 32%|███▏      | 324/1000 [00:00<00:00, 1102.25it/s] 44%|████▍     | 444/1000 [00:00<00:00, 975.43it/s]  60%|██████    | 601/1000 [00:00<00:00, 1157.62it/s] 77%|███████▋  | 768/1000 [00:00<00:00, 1311.87it/s] 93%|█████████▎| 934/1000 [00:00<00:00, 1417.39it/s]100%|██████████| 1000/1000 [00:00<00:00, 1304.53it/s]
2025-01-09:13:13:05,701 INFO     [evaluator.py:496] Running loglikelihood requests
Running loglikelihood requests:   0%|          | 0/3000 [00:00<?, ?it/s]Running loglikelihood requests:   0%|          | 1/3000 [00:05<4:56:01,  5.92s/it]Running loglikelihood requests:   2%|▏         | 65/3000 [00:06<03:39, 13.39it/s] Running loglikelihood requests:   4%|▍         | 129/3000 [00:10<03:11, 14.96it/s]Running loglikelihood requests:   6%|▋         | 193/3000 [00:11<01:54, 24.47it/s]Running loglikelihood requests:   9%|▊         | 257/3000 [00:11<01:18, 34.98it/s]Running loglikelihood requests:  11%|█         | 321/3000 [00:12<00:58, 46.05it/s]Running loglikelihood requests:  13%|█▎        | 385/3000 [00:12<00:45, 57.23it/s]Running loglikelihood requests:  15%|█▍        | 449/3000 [00:13<00:37, 68.33it/s]Running loglikelihood requests:  17%|█▋        | 513/3000 [00:14<00:31, 78.05it/s]Running loglikelihood requests:  19%|█▉        | 577/3000 [00:14<00:27, 87.76it/s]Running loglikelihood requests:  21%|██▏       | 641/3000 [00:15<00:24, 96.56it/s]Running loglikelihood requests:  24%|██▎       | 705/3000 [00:15<00:21, 105.38it/s]Running loglikelihood requests:  26%|██▌       | 769/3000 [00:16<00:20, 110.60it/s]Running loglikelihood requests:  28%|██▊       | 833/3000 [00:16<00:18, 116.92it/s]Running loglikelihood requests:  30%|██▉       | 897/3000 [00:17<00:17, 121.71it/s]Running loglikelihood requests:  32%|███▏      | 961/3000 [00:17<00:16, 126.64it/s]Running loglikelihood requests:  34%|███▍      | 1025/3000 [00:18<00:15, 129.56it/s]Running loglikelihood requests:  36%|███▋      | 1089/3000 [00:18<00:14, 134.65it/s]Running loglikelihood requests:  38%|███▊      | 1153/3000 [00:18<00:13, 138.23it/s]Running loglikelihood requests:  41%|████      | 1217/3000 [00:19<00:12, 144.53it/s]Running loglikelihood requests:  43%|████▎     | 1281/3000 [00:19<00:11, 149.58it/s]Running loglikelihood requests:  45%|████▍     | 1345/3000 [00:20<00:10, 153.82it/s]Running loglikelihood requests:  47%|████▋     | 1409/3000 [00:20<00:10, 157.99it/s]Running loglikelihood requests:  49%|████▉     | 1473/3000 [00:20<00:09, 161.79it/s]Running loglikelihood requests:  51%|█████     | 1537/3000 [00:21<00:08, 164.87it/s]Running loglikelihood requests:  53%|█████▎    | 1601/3000 [00:21<00:08, 167.45it/s]Running loglikelihood requests:  56%|█████▌    | 1665/3000 [00:21<00:07, 171.33it/s]Running loglikelihood requests:  58%|█████▊    | 1729/3000 [00:22<00:07, 173.47it/s]Running loglikelihood requests:  60%|█████▉    | 1793/3000 [00:22<00:06, 174.81it/s]Running loglikelihood requests:  62%|██████▏   | 1857/3000 [00:22<00:06, 179.62it/s]Running loglikelihood requests:  64%|██████▍   | 1921/3000 [00:23<00:05, 183.11it/s]Running loglikelihood requests:  66%|██████▌   | 1985/3000 [00:23<00:05, 185.89it/s]Running loglikelihood requests:  68%|██████▊   | 2049/3000 [00:23<00:05, 188.36it/s]Running loglikelihood requests:  70%|███████   | 2113/3000 [00:24<00:04, 189.91it/s]Running loglikelihood requests:  73%|███████▎  | 2177/3000 [00:24<00:04, 192.29it/s]Running loglikelihood requests:  75%|███████▍  | 2241/3000 [00:24<00:03, 192.60it/s]Running loglikelihood requests:  77%|███████▋  | 2305/3000 [00:25<00:03, 195.70it/s]Running loglikelihood requests:  79%|███████▉  | 2369/3000 [00:25<00:03, 199.45it/s]Running loglikelihood requests:  81%|████████  | 2433/3000 [00:25<00:02, 203.15it/s]Running loglikelihood requests:  83%|████████▎ | 2497/3000 [00:26<00:02, 209.65it/s]Running loglikelihood requests:  85%|████████▌ | 2561/3000 [00:26<00:02, 218.55it/s]Running loglikelihood requests:  88%|████████▊ | 2625/3000 [00:26<00:01, 225.20it/s]Running loglikelihood requests:  90%|████████▉ | 2689/3000 [00:26<00:01, 232.33it/s]Running loglikelihood requests:  92%|█████████▏| 2753/3000 [00:27<00:01, 241.36it/s]Running loglikelihood requests:  94%|█████████▍| 2817/3000 [00:27<00:00, 248.89it/s]Running loglikelihood requests:  96%|█████████▌| 2881/3000 [00:27<00:00, 264.50it/s]Running loglikelihood requests:  98%|█████████▊| 2945/3000 [00:27<00:00, 289.19it/s]Running loglikelihood requests: 100%|██████████| 3000/3000 [00:27<00:00, 107.88it/s]
2025-01-09:13:13:41,369 INFO     [evaluation_tracker.py:269] Output path not provided, skipping saving results aggregated
Passed argument batch_size = auto:16.0. Detecting largest batch size
Determined largest batch size: 64
Passed argument batch_size = auto:16.0. Detecting largest batch size
Determined largest batch size: 64
hf (pretrained=EleutherAI/pythia-2.8b,trust_remote_code=True,parallelize=True,max_length=2048,trust_remote_code=True), gen_kwargs: (None), limit: 1000.0, num_fewshot: None, batch_size: auto:16 (64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64,64)
|     Tasks     |Version|Filter|n-shot|Metric|   |Value |   |Stderr|
|---------------|------:|------|-----:|------|---|-----:|---|------|
|vaxxstance_2021|      1|none  |     0|acc   |↑  |0.4410|±  |0.0157|
|               |       |none  |     0|f1    |↑  |0.4013|±  |   N/A|

